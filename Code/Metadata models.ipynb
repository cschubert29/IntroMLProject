{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "df = pd.read_csv('../bills93-114.csv',sep=';',encoding='cp1252')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 294524 entries, 0 to 294523\n",
      "Data columns (total 48 columns):\n",
      "BillID        294524 non-null object\n",
      "BillNum       294524 non-null int64\n",
      "BillType      294524 non-null object\n",
      "Chamber       294524 non-null int64\n",
      "Cong          294524 non-null int64\n",
      "Cosponsr      294485 non-null float64\n",
      "IntrDate      294524 non-null object\n",
      "Mult          294485 non-null float64\n",
      "MultNo        294485 non-null float64\n",
      "PLaw          294524 non-null int64\n",
      "Private       294524 non-null int64\n",
      "Title         294524 non-null object\n",
      "Veto          294524 non-null int64\n",
      "Class         90487 non-null float64\n",
      "ComC          294485 non-null float64\n",
      "ComR          294485 non-null float64\n",
      "CumHServ      294485 non-null float64\n",
      "CumSServ      294485 non-null float64\n",
      "Delegate      294524 non-null int64\n",
      "District      294485 non-null float64\n",
      "DW1           294285 non-null object\n",
      "FrstConH      294485 non-null float64\n",
      "FrstConS      294485 non-null float64\n",
      "Gender        294524 non-null int64\n",
      "MemberID      294522 non-null object\n",
      "MRef          294524 non-null int64\n",
      "NameFirst     294524 non-null object\n",
      "NameFull      294524 non-null object\n",
      "NameLast      294524 non-null object\n",
      "Party         294492 non-null float64\n",
      "PooleID       292630 non-null float64\n",
      "Postal        294524 non-null object\n",
      "State         294524 non-null int64\n",
      "URL           294336 non-null object\n",
      "ChRef         294524 non-null int64\n",
      "RankRef       294524 non-null int64\n",
      "PassH         294524 non-null int64\n",
      "PassS         294524 non-null int64\n",
      "PLawDate      11600 non-null object\n",
      "PLawNum       11990 non-null object\n",
      "ImpBill       294336 non-null float64\n",
      "SubChRef      241197 non-null float64\n",
      "SubRankRef    241197 non-null float64\n",
      "Majority      294524 non-null int64\n",
      "ReportH       294524 non-null int64\n",
      "ReportS       294524 non-null int64\n",
      "Major         237658 non-null float64\n",
      "Minor         237656 non-null float64\n",
      "dtypes: float64(18), int64(17), object(13)\n",
      "memory usage: 107.9+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BillID</th>\n",
       "      <th>BillNum</th>\n",
       "      <th>BillType</th>\n",
       "      <th>Chamber</th>\n",
       "      <th>Cong</th>\n",
       "      <th>Cosponsr</th>\n",
       "      <th>IntrDate</th>\n",
       "      <th>Mult</th>\n",
       "      <th>MultNo</th>\n",
       "      <th>PLaw</th>\n",
       "      <th>...</th>\n",
       "      <th>PLawDate</th>\n",
       "      <th>PLawNum</th>\n",
       "      <th>ImpBill</th>\n",
       "      <th>SubChRef</th>\n",
       "      <th>SubRankRef</th>\n",
       "      <th>Majority</th>\n",
       "      <th>ReportH</th>\n",
       "      <th>ReportS</th>\n",
       "      <th>Major</th>\n",
       "      <th>Minor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93-HCONRES-1</td>\n",
       "      <td>1</td>\n",
       "      <td>hconres</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1973-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93-HCONRES-2</td>\n",
       "      <td>2</td>\n",
       "      <td>hconres</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1973-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93-HCONRES-3</td>\n",
       "      <td>3</td>\n",
       "      <td>hconres</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1973-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93-HCONRES-4</td>\n",
       "      <td>4</td>\n",
       "      <td>hconres</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1973-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93-HCONRES-5</td>\n",
       "      <td>5</td>\n",
       "      <td>hconres</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1973-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         BillID  BillNum BillType  Chamber  Cong  Cosponsr    IntrDate  Mult  \\\n",
       "0  93-HCONRES-1        1  hconres        0    93       0.0  1973-01-03   0.0   \n",
       "1  93-HCONRES-2        2  hconres        0    93       0.0  1973-01-03   0.0   \n",
       "2  93-HCONRES-3        3  hconres        0    93       0.0  1973-01-03   0.0   \n",
       "3  93-HCONRES-4        4  hconres        0    93       0.0  1973-01-03   0.0   \n",
       "4  93-HCONRES-5        5  hconres        0    93       0.0  1973-01-03   0.0   \n",
       "\n",
       "   MultNo  PLaw  ...    PLawDate PLawNum  ImpBill  SubChRef  SubRankRef  \\\n",
       "0     1.0     0  ...         NaN     NaN      0.0       NaN         NaN   \n",
       "1     1.0     0  ...         NaN     NaN      0.0       NaN         NaN   \n",
       "2     1.0     0  ...         NaN     NaN      0.0       NaN         NaN   \n",
       "3     1.0     0  ...         NaN     NaN      0.0       NaN         NaN   \n",
       "4     1.0     0  ...         NaN     NaN      0.0       NaN         NaN   \n",
       "\n",
       "   Majority  ReportH  ReportS  Major  Minor  \n",
       "0         1        0        0    NaN    NaN  \n",
       "1         1        0        0    NaN    NaN  \n",
       "2         1        0        0    NaN    NaN  \n",
       "3         0        0        0    NaN    NaN  \n",
       "4         0        0        0    NaN    NaN  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df['Cong']>=107]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BillID</th>\n",
       "      <th>BillNum</th>\n",
       "      <th>BillType</th>\n",
       "      <th>Chamber</th>\n",
       "      <th>Cong</th>\n",
       "      <th>Cosponsr</th>\n",
       "      <th>IntrDate</th>\n",
       "      <th>Mult</th>\n",
       "      <th>MultNo</th>\n",
       "      <th>PLaw</th>\n",
       "      <th>...</th>\n",
       "      <th>PLawDate</th>\n",
       "      <th>PLawNum</th>\n",
       "      <th>ImpBill</th>\n",
       "      <th>SubChRef</th>\n",
       "      <th>SubRankRef</th>\n",
       "      <th>Majority</th>\n",
       "      <th>ReportH</th>\n",
       "      <th>ReportS</th>\n",
       "      <th>Major</th>\n",
       "      <th>Minor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197297</th>\n",
       "      <td>107-HCONRES-1</td>\n",
       "      <td>1</td>\n",
       "      <td>hconres</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197298</th>\n",
       "      <td>107-HCONRES-2</td>\n",
       "      <td>2</td>\n",
       "      <td>hconres</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197299</th>\n",
       "      <td>107-HCONRES-3</td>\n",
       "      <td>3</td>\n",
       "      <td>hconres</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2001-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197300</th>\n",
       "      <td>107-HCONRES-4</td>\n",
       "      <td>4</td>\n",
       "      <td>hconres</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2001-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197301</th>\n",
       "      <td>107-HCONRES-5</td>\n",
       "      <td>5</td>\n",
       "      <td>hconres</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2001-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               BillID  BillNum BillType  Chamber  Cong  Cosponsr    IntrDate  \\\n",
       "197297  107-HCONRES-1        1  hconres        0   107       0.0  2001-01-03   \n",
       "197298  107-HCONRES-2        2  hconres        0   107       0.0  2001-01-03   \n",
       "197299  107-HCONRES-3        3  hconres        0   107      38.0  2001-01-03   \n",
       "197300  107-HCONRES-4        4  hconres        0   107      40.0  2001-01-03   \n",
       "197301  107-HCONRES-5        5  hconres        0   107       3.0  2001-01-03   \n",
       "\n",
       "        Mult  MultNo  PLaw  ...    PLawDate PLawNum  ImpBill  SubChRef  \\\n",
       "197297   0.0     1.0     0  ...         NaN     NaN      0.0       NaN   \n",
       "197298   0.0     1.0     0  ...         NaN     NaN      0.0       NaN   \n",
       "197299   0.0     1.0     0  ...         NaN     NaN      0.0       NaN   \n",
       "197300   0.0     1.0     0  ...         NaN     NaN      0.0       NaN   \n",
       "197301   0.0     1.0     0  ...         NaN     NaN      0.0       NaN   \n",
       "\n",
       "        SubRankRef  Majority  ReportH  ReportS  Major  Minor  \n",
       "197297         NaN         1        0        0    NaN    NaN  \n",
       "197298         NaN         1        0        0    NaN    NaN  \n",
       "197299         NaN         0        0        0    NaN    NaN  \n",
       "197300         NaN         0        0        0    NaN    NaN  \n",
       "197301         NaN         0        0        0    NaN    NaN  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified Train/Test split\n",
    "\n",
    "\n",
    "stratified_split = StratifiedShuffleSplit(n_splits=2, test_size=0.33)\n",
    "for train_index, test_index in stratified_split.split(data_x, data_y):\n",
    "    x_train, x_test = data_x[train_index], data_x[test_index]\n",
    "    y_train, y_test = data_y[train_index], data_y[test_index]\n",
    "\n",
    "# transform matrix of plots into lists to pass to a TfidfVectorizer\n",
    "train_x = [x[0].strip() for x in x_train.tolist()]\n",
    "test_x = [x[0].strip() for x in x_test.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words model\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count Vectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "        fit_prior=True, class_prior=None))),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'clf__estimator__alpha': (1e-2, 1e-3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "...                      ('tfidf', TfidfTransformer()),\n",
    "...                      ('clf', MultinomialNB()),\n",
    "... ])\n",
    "\n",
    "text_clf = text_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance on test set\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "predicted = text_clf.predict(twenty_test.data)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear SVM\n",
    "\n",
    "\n",
    ">>> text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "...                      ('tfidf', TfidfTransformer()),\n",
    "...                      ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "...                                            alpha=1e-3, n_iter=5, random_state=42)),\n",
    "... ])\n",
    ">>> _ = text_clf_svm.fit(twenty_train.data, twenty_train.target)\n",
    ">>> predicted_svm = text_clf_svm.predict(twenty_test.data)\n",
    ">>> np.mean(predicted_svm == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search\n",
    "\n",
    ">>> parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "...               'tfidf__use_idf': (True, False),\n",
    "...               'clf__alpha': (1e-2, 1e-3),\n",
    "... }\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline, parameters, cv=2, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(train_x, train_y)\n",
    "\n",
    "print\n",
    "print(\"Best parameters set:\")\n",
    "print grid_search_tune.best_estimator_.steps\n",
    "print\n",
    "\n",
    "# measuring performance on test set\n",
    "print \"Applying best classifier on test data:\"\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(test_x)\n",
    "\n",
    "print classification_report(test_y, predictions, target_names=genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from sklearn.model_selection import GridSearchCV\n",
    ">>> parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "...               'tfidf__use_idf': (True, False),\n",
    "...               'clf-svm__alpha': (1e-2, 1e-3),\n",
    "... }\n",
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(twenty_train.data, twenty_train.target)\n",
    "gs_clf_svm.best_score_\n",
    "gs_clf_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings model\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train a word embedding network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a vocabulary\n",
    "\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train doc2vec\n",
    "\n",
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build final feature vector for classifier\n",
    "\n",
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressorsdef vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Logistic Regression Classifier\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained word-embedding vectors \n",
    "embeddings_index = {}\n",
    "for i, line in enumerate(open('data/wiki-news-300d-1M.vec')):\n",
    "    values = line.split()\n",
    "    embeddings_index[values[0]] = numpy.asarray(values[1:], dtype='float32')\n",
    "\n",
    "# create a tokenizer \n",
    "token = text.Tokenizer()\n",
    "token.fit_on_texts(trainDF['text'])\n",
    "word_index = token.word_index\n",
    "\n",
    "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
    "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=70)\n",
    "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=70)\n",
    "\n",
    "# create token-embedding mapping\n",
    "embedding_matrix = numpy.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding + Convolutional Neural Network\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, batch_size, output_size, in_channels, out_channels, kernel_heights, stride, padding, keep_probab, vocab_size, embedding_length, weights):\n",
    "\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tArguments\n",
    "\n",
    "\t\t---------\n",
    "\n",
    "\t\tbatch_size : Size of each batch which is same as the batch_size of the data returned by the TorchText BucketIterator\n",
    "\n",
    "\t\toutput_size : 2 = (pos, neg)\n",
    "\n",
    "\t\tin_channels : Number of input channels. Here it is 1 as the input data has dimension = (batch_size, num_seq, embedding_length)\n",
    "\n",
    "\t\tout_channels : Number of output channels after convolution operation performed on the input matrix\n",
    "\n",
    "\t\tkernel_heights : A list consisting of 3 different kernel_heights. Convolution will be performed 3 times and finally results from each kernel_height will be concatenated.\n",
    "\n",
    "\t\tkeep_probab : Probability of retaining an activation node during dropout operation\n",
    "\n",
    "\t\tvocab_size : Size of the vocabulary containing unique words\n",
    "\n",
    "\t\tembedding_length : Embedding dimension of GloVe word embeddings\n",
    "\n",
    "\t\tweights : Pre-trained GloVe word_embeddings which we will use to create our word_embedding look-up table\n",
    "\n",
    "\t\t--------\n",
    "\n",
    "\t\t\n",
    "\n",
    "\t\t\"\"\"\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.output_size = output_size\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_heights = kernel_heights\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_length = embedding_length\n",
    "\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_length)\n",
    "        self.word_embeddings.weight = nn.Parameter(weights, requires_grad=False)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, (kernel_heights[0], embedding_length), stride, padding)\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, (kernel_heights[1], embedding_length), stride, padding)\n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels, (kernel_heights[2], embedding_length), stride, padding)\n",
    "        self.dropout = nn.Dropout(keep_probab)\n",
    "        self.label = nn.Linear(len(kernel_heights)*out_channels, output_size)\n",
    "\n",
    "    def conv_block(self, input, conv_layer):\n",
    "\n",
    "        conv_out = conv_layer(input)# conv_out.size() = (batch_size, out_channels, dim, 1)\n",
    "        activation = F.relu(conv_out.squeeze(3))# activation.size() = (batch_size, out_channels, dim1)\n",
    "        max_out = F.max_pool1d(activation, activation.size()[2]).squeeze(2)# maxpool_out.size() = (batch_size, out_channels)\n",
    "\n",
    "        return max_out\n",
    "\n",
    "\n",
    "    def forward(self, input_sentences, batch_size=None):\n",
    "\n",
    "\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tThe idea of the Convolutional Neural Netwok for Text Classification is very simple. We perform convolution operation on the embedding matrix \n",
    "\n",
    "\t\twhose shape for each batch is (num_seq, embedding_length) with kernel of varying height but constant width which is same as the embedding_length.\n",
    "\n",
    "\t\tWe will be using ReLU activation after the convolution operation and then for each kernel height, we will use max_pool operation on each tensor \n",
    "\n",
    "\t\tand will filter all the maximum activation for every channel and then we will concatenate the resulting tensors. This output is then fully connected\n",
    "\n",
    "\t\tto the output layers consisting two units which basically gives us the logits for both positive and negative classes.\n",
    "\n",
    "\t\t\n",
    "\n",
    "\t\tParameters\n",
    "\n",
    "\t\t----------\n",
    "\n",
    "\t\tinput_sentences: input_sentences of shape = (batch_size, num_sequences)\n",
    "\n",
    "\t\tbatch_size : default = None. Used only for prediction on a single sentence after training (batch_size = 1)\n",
    "\n",
    "\t\t\n",
    "\n",
    "\t\tReturns\n",
    "\n",
    "\t\t-------\n",
    "\n",
    "\t\tOutput of the linear layer containing logits for pos & neg class.\n",
    "\n",
    "\t\tlogits.size() = (batch_size, output_size)\n",
    "\n",
    "\t\t\n",
    "\n",
    "\t\t\"\"\"\n",
    "\n",
    "\n",
    "        input = self.word_embeddings(input_sentences)\n",
    "        # input.size() = (batch_size, num_seq, embedding_length)\n",
    "        input = input.unsqueeze(1)\n",
    "        # input.size() = (batch_size, 1, num_seq, embedding_length)\n",
    "        max_out1 = self.conv_block(input, self.conv1)\n",
    "        max_out2 = self.conv_block(input, self.conv2)\n",
    "        max_out3 = self.conv_block(input, self.conv3)\n",
    "\n",
    "\n",
    "        all_out = torch.cat((max_out1, max_out2, max_out3), 1)\n",
    "        # all_out.size() = (batch_size, num_kernels*out_channels)\n",
    "\n",
    "        fc_in = self.dropout(all_out)\n",
    "\n",
    "        # fc_in.size()) = (batch_size, num_kernels*out_channels)\n",
    "\n",
    "        logits = self.label(fc_in)\n",
    "\n",
    "\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on new data (115th Congress)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
