{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import doc2vec\n",
    "\n",
    "from collections import OrderedDict\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load x_train, y_train, x_test, y_test\n",
    "x_train=pd.read_csv('../Data/text x_train.csv',header=None,names=['Index','Text'])\n",
    "y_train = pd.read_csv('../Data/text y_train.csv',header=None,names=['Index','Label'])\n",
    "x_test = pd.read_csv('../Data/text x_test.csv',header=None,names=['Index','Text'])\n",
    "y_test = pd.read_csv('../Data/text y_test.csv',header=None, names=['Index','Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents = list(x_train.itertuples(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_documents = list(x_test.itertuples(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Transform data\n",
    "docs = []\n",
    "stops=set(stopwords.words('english'))\n",
    "analyzedDocument = namedtuple('AnalyzedDocument', 'words tags')\n",
    "for d in train_documents:\n",
    "    #tokenize\n",
    "    tokens = simple_preprocess(d[1])\n",
    "    #Remove stop words\n",
    "    filt_doc = [word for word in tokens if word not in stops]\n",
    "#     print(filt_doc)\n",
    "    docs.append(analyzedDocument(filt_doc,[d[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform test data\n",
    "#tokenize\n",
    "tokens =[simple_preprocess(doc[1]) for doc in test_documents]\n",
    "#remove stop words\n",
    "filt_test_docs = [[word for word in token if word not in stops]\n",
    "            for token in tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Train doc2vec model\n",
    "model=doc2vec.Doc2Vec(docs,dm=1, vector_size=100, window=10, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=20, workers=4, alpha=0.05, comment='alpha=0.05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "model.save('doc2vec_model_dm1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = doc2vec.Doc2Vec.load('doc2vec_model_dm1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Build the final feature vectors for the classifier\n",
    "#use infer_vector() to “retrain” the document vector\n",
    "#vector = model.infer_vector([\"system\", \"response\"])\n",
    "\n",
    "train_regressors = [model.infer_vector(doc.words, steps=10) for doc in docs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cschu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(train_regressors, y_train['Label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Infer vectors for test set\n",
    "test_regressors = [model.infer_vector(doc, steps=20) for doc in filt_test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test_regressors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.88      0.99      0.04      0.93      0.20      0.04     20295\n",
      "          1       0.47      0.04      0.99      0.07      0.20      0.04      2975\n",
      "\n",
      "avg / total       0.82      0.87      0.16      0.82      0.20      0.04     23270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report_imbalanced(y_test['Label'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8715513536742587"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy on test set\n",
    "score=metrics.accuracy_score(y_test['Label'],y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[20160   135]\n",
      " [ 2854   121]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "print('Confusion matrix:')\n",
    "print(metrics.confusion_matrix(y_test['Label'],y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing the class before classification\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 47354), (1, 6940)]\n"
     ]
    }
   ],
   "source": [
    "#Initial class distribution\n",
    "print(sorted(Counter(y_train['Label']).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random under-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cschu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 679 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#make pipeline. include random under sampling\n",
    "under_sample_pipe = make_pipeline_imb(RandomUnderSampler(),LogisticRegression())\n",
    "under_sample_pipe.fit(train_regressors, y_train['Label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.92      0.71      0.57      0.80      0.64      0.41     20295\n",
      "          1       0.22      0.57      0.71      0.32      0.64      0.40      2975\n",
      "\n",
      "avg / total       0.83      0.69      0.59      0.74      0.64      0.41     23270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Make predictions on test set\n",
    "y_pred = under_sample_pipe.predict(test_regressors)\n",
    "print(classification_report_imbalanced(y_test['Label'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6883111302105716"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy on test set\n",
    "score=metrics.accuracy_score(y_test['Label'],y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[14314  5981]\n",
      " [ 1272  1703]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "print('Confusion matrix:')\n",
    "print(metrics.confusion_matrix(y_test['Label'],y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cschu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#make pipeline. include random under sampling\n",
    "over_sample_pipe = make_pipeline_imb(RandomOverSampler(),LogisticRegression())\n",
    "over_sample_pipe.fit(train_regressors, y_train['Label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.92      0.70      0.58      0.80      0.64      0.41     20295\n",
      "          1       0.22      0.58      0.70      0.32      0.64      0.40      2975\n",
      "\n",
      "avg / total       0.83      0.69      0.60      0.74      0.64      0.41     23270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Make predictions on test set\n",
    "y_pred = over_sample_pipe.predict(test_regressors)\n",
    "print(classification_report_imbalanced(y_test['Label'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6879673399226471"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy on test set\n",
    "score=metrics.accuracy_score(y_test['Label'],y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[14284  6011]\n",
      " [ 1250  1725]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "print('Confusion matrix:')\n",
    "print(metrics.confusion_matrix(y_test['Label'],y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cschu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#make pipeline. include random under sampling\n",
    "smote_pipe = make_pipeline_imb(SMOTE(random_state=42),LogisticRegression())\n",
    "smote_pipe.fit(train_regressors, y_train['Label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.93      0.62      0.66      0.74      0.64      0.41     20295\n",
      "          1       0.20      0.66      0.62      0.31      0.64      0.41      2975\n",
      "\n",
      "avg / total       0.83      0.63      0.65      0.69      0.64      0.41     23270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Make predictions on test set\n",
    "y_pred = smote_pipe.predict(test_regressors)\n",
    "print(classification_report_imbalanced(y_test['Label'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6276321443919209"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy on test set\n",
    "score=metrics.accuracy_score(y_test['Label'],y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[12644  7651]\n",
      " [ 1014  1961]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "print('Confusion matrix:')\n",
    "print(metrics.confusion_matrix(y_test['Label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC plot\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(doc2vec_model, corpus_size, vectors_size, vectors_type):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Get vectors from trained doc2vec model\n",
    "\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "\n",
    "    :param corpus_size: Size of the data\n",
    "\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "\n",
    "    :return: list of vectors\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "\n",
    "    for i in range(0, corpus_size):\n",
    "\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "\n",
    "        vectors[i] = doc2vec_model.docvecs[prefix]\n",
    "\n",
    "    return vectors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_doc2vec(corpus):\n",
    "\n",
    "    logging.info(\"Building Doc2Vec vocabulary\")\n",
    "\n",
    "    d2v = doc2vec.Doc2Vec(min_count=1,  # Ignores all words with total frequency lower than this\n",
    "\n",
    "                          window=10,  # The maximum distance between the current and predicted word within a sentence\n",
    "\n",
    "                          vector_size=300,  # Dimensionality of the generated feature vectors\n",
    "\n",
    "                          workers=5,  # Number of worker threads to train the model\n",
    "\n",
    "                          alpha=0.025,  # The initial learning rate\n",
    "\n",
    "                          min_alpha=0.00025,  # Learning rate will linearly drop to min_alpha as training progresses\n",
    "\n",
    "                          dm=1)  # dm defines the training algorithm. If dm=1 means ‘distributed memory’ (PV-DM)\n",
    "\n",
    "                                 # and dm =0 means ‘distributed bag of words’ (PV-DBOW)\n",
    "\n",
    "    d2v.build_vocab(corpus)\n",
    "\n",
    "\n",
    "\n",
    "    logging.info(\"Training Doc2Vec model\")\n",
    "\n",
    "    # 10 epochs take around 10 minutes on my machine (i7), if you have more time/computational power make it 20\n",
    "\n",
    "    for epoch in range(10):\n",
    "\n",
    "        logging.info('Training iteration #{0}'.format(epoch))\n",
    "\n",
    "        d2v.train(corpus, total_examples=d2v.corpus_count, epochs=d2v.iter)\n",
    "\n",
    "        # shuffle the corpus\n",
    "\n",
    "        random.shuffle(corpus)\n",
    "\n",
    "        # decrease the learning rate\n",
    "\n",
    "        d2v.alpha -= 0.0002\n",
    "\n",
    "        # fix the learning rate, no decay\n",
    "\n",
    "        d2v.min_alpha = d2v.alpha\n",
    "\n",
    "\n",
    "\n",
    "    logging.info(\"Saving trained Doc2Vec model\")\n",
    "\n",
    "    d2v.save(\"d2v.model\")\n",
    "\n",
    "    return d2v\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_classifier(d2v, training_vectors, training_labels):\n",
    "\n",
    "    logging.info(\"Classifier training\")\n",
    "\n",
    "    train_vectors = get_vectors(d2v, len(training_vectors), 300, 'Train')\n",
    "\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    model.fit(train_vectors, np.array(training_labels))\n",
    "\n",
    "    training_predictions = model.predict(train_vectors)\n",
    "\n",
    "    logging.info('Training predicted classes: {}'.format(np.unique(training_predictions)))\n",
    "\n",
    "    logging.info('Training accuracy: {}'.format(accuracy_score(training_labels, training_predictions)))\n",
    "\n",
    "    logging.info('Training F1 score: {}'.format(f1_score(training_labels, training_predictions, average='weighted')))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_classifier(d2v, classifier, testing_vectors, testing_labels):\n",
    "\n",
    "    logging.info(\"Classifier testing\")\n",
    "\n",
    "    test_vectors = get_vectors(d2v, len(testing_vectors), 300, 'Test')\n",
    "\n",
    "    testing_predictions = classifier.predict(test_vectors)\n",
    "\n",
    "    logging.info('Testing predicted classes: {}'.format(np.unique(testing_predictions)))\n",
    "\n",
    "    logging.info('Testing accuracy: {}'.format(accuracy_score(testing_labels, testing_predictions)))\n",
    "\n",
    "    logging.info('Testing F1 score: {}'.format(f1_score(testing_labels, testing_predictions, average='weighted')))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    x_train, x_test, y_train, y_test, all_data = read_dataset('dataset.csv')\n",
    "\n",
    "    d2v_model = train_doc2vec(all_data)\n",
    "\n",
    "    classifier = train_classifier(d2v_model, x_train, y_train)\n",
    "\n",
    "    test_classifier(d2v_model, classifier, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc2Vec(dm=1, vector_size=100, window=10, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=20, workers=cores, alpha=0.05, comment='alpha=0.05'),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc2Vec(dm=0, vector_size=100, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=20, workers=cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model (set min_count = 1, if you want the model to work with the provided example data set\n",
    "\n",
    "model = doc2vec.Doc2Vec(docs, size = 100, window = 300, min_count = 1, workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(sents, size=1, window=100, iter=20, dm=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = doc2vec.Doc2Vec(docs, size = 300, window = 10, dm=1, negative=5, hs=0, min_count = 1, workers = 4, iter = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[5]:\n",
    "model = gensim.models.doc2vec.Doc2Vec(size=100, min_count=2, iter=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "\n",
    "simple_models = [\n",
    "    # PV-DBOW plain\n",
    "    Doc2Vec(dm=0, vector_size=100, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=20, workers=cores),\n",
    "    # PV-DM w/ default averaging; a higher starting alpha may improve CBOW/PV-DM modes\n",
    "    Doc2Vec(dm=1, vector_size=100, window=10, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=20, workers=cores, alpha=0.05, comment='alpha=0.05'),\n",
    "    # PV-DM w/ concatenation - big, slow, experimental mode\n",
    "    # window=5 (both sides) approximates paper's apparent 10-word total window size\n",
    "    Doc2Vec(dm=1, dm_concat=1, vector_size=100, window=5, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=20, workers=cores),\n",
    "]\n",
    "\n",
    "for model in simple_models:\n",
    "    model.build_vocab(alldocs)\n",
    "    print(\"%s vocabulary scanned & state initialized\" % model)\n",
    "\n",
    "models_by_name = OrderedDict((str(model), model) for model in simple_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# from gensim.models import Doc2Vec\n",
    "\n",
    "# from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.autograd import Variable\n",
    "# from torch.nn import functional as F\n",
    "\n",
    "# import re\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cschu\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf_logistic = LogisticRegression().fit(X_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8877776549895016"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_logistic.score(X_new,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8721529866781264"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performance on test set\n",
    "predicted = clf_logistic.predict(X_test_new)\n",
    "score=metrics.accuracy_score(y_test,predicted)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93     20295\n",
      "          1       0.00      0.00      0.00      2975\n",
      "\n",
      "avg / total       0.76      0.87      0.81     23270\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cschu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Classification report\n",
    "print('Classification report:')\n",
    "print(metrics.classification_report(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[20295     0]\n",
      " [ 2975     0]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "print('Confusion matrix:')\n",
    "print(metrics.confusion_matrix(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove punctuation from each word\n",
    "# import string\n",
    "# table = str.maketrans('', '', string.punctuation)\n",
    "# stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# # remove remaining tokens that are not alphabetic\n",
    "# words = [word for word in stripped if word.isalpha()]\n",
    "\n",
    "# # filter out stop words\n",
    "# from nltk.corpus import stopwords\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "# words = [w for w in words if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stratified Train/Test split\n",
    "\n",
    "# stratified_split = StratifiedShuffleSplit(n_splits=2, test_size=0.3)\n",
    "# for train_index, test_index in stratified_split.split(X, y):\n",
    "#     x_train, x_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "# # transform matrix of plots into lists to pass to a TfidfVectorizer\n",
    "# train_x = [x[0].strip() for x in x_train.tolist()]\n",
    "# test_x = [x[0].strip() for x in x_test.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Naive Bayes\n",
    "\n",
    "# pipeline = Pipeline([\n",
    "#     ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "#     ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "#         fit_prior=True, class_prior=None))),\n",
    "# ])\n",
    "# parameters = {\n",
    "#     'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "#     'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "#     'clf__estimator__alpha': (1e-2, 1e-3)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "# split the dataset into training and validation datasets \n",
    "train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "\n",
    "# Naive Bayes on Count Vectors\n",
    "accuracy = train_model(MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
    "print(\"NB, Count Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy = train_model(MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"NB, Word TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read metadata to obtain the class labels\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "        fit_prior=True, class_prior=None))),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'clf__estimator__alpha': (1e-2, 1e-3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "...                      ('tfidf', TfidfTransformer()),\n",
    "...                      ('clf', MultinomialNB()),\n",
    "... ])\n",
    "\n",
    "text_clf = text_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance on test set\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "predicted = text_clf.predict(twenty_test.data)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear SVM\n",
    "\n",
    "\n",
    ">>> text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "...                      ('tfidf', TfidfTransformer()),\n",
    "...                      ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "...                                            alpha=1e-3, n_iter=5, random_state=42)),\n",
    "... ])\n",
    ">>> _ = text_clf_svm.fit(twenty_train.data, twenty_train.target)\n",
    ">>> predicted_svm = text_clf_svm.predict(twenty_test.data)\n",
    ">>> np.mean(predicted_svm == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search\n",
    "\n",
    ">>> parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "...               'tfidf__use_idf': (True, False),\n",
    "...               'clf__alpha': (1e-2, 1e-3),\n",
    "... }\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline, parameters, cv=2, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(train_x, train_y)\n",
    "\n",
    "print\n",
    "print(\"Best parameters set:\")\n",
    "print grid_search_tune.best_estimator_.steps\n",
    "print\n",
    "\n",
    "# measuring performance on test set\n",
    "print \"Applying best classifier on test data:\"\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(test_x)\n",
    "\n",
    "print classification_report(test_y, predictions, target_names=genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from sklearn.model_selection import GridSearchCV\n",
    ">>> parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "...               'tfidf__use_idf': (True, False),\n",
    "...               'clf-svm__alpha': (1e-2, 1e-3),\n",
    "... }\n",
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(twenty_train.data, twenty_train.target)\n",
    "gs_clf_svm.best_score_\n",
    "gs_clf_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings model\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train a word embedding network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a vocabulary\n",
    "\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train doc2vec\n",
    "\n",
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build final feature vector for classifier\n",
    "\n",
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressorsdef vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Logistic Regression Classifier\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained word-embedding vectors \n",
    "embeddings_index = {}\n",
    "for i, line in enumerate(open('data/wiki-news-300d-1M.vec')):\n",
    "    values = line.split()\n",
    "    embeddings_index[values[0]] = numpy.asarray(values[1:], dtype='float32')\n",
    "\n",
    "# create a tokenizer \n",
    "token = text.Tokenizer()\n",
    "token.fit_on_texts(trainDF['text'])\n",
    "word_index = token.word_index\n",
    "\n",
    "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
    "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=70)\n",
    "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=70)\n",
    "\n",
    "# create token-embedding mapping\n",
    "embedding_matrix = numpy.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding + Convolutional Neural Network\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, batch_size, output_size, in_channels, out_channels, kernel_heights, stride, padding, keep_probab, vocab_size, embedding_length, weights):\n",
    "\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tArguments\n",
    "\n",
    "\t\t---------\n",
    "\n",
    "\t\tbatch_size : Size of each batch which is same as the batch_size of the data returned by the TorchText BucketIterator\n",
    "\n",
    "\t\toutput_size : 2 = (pos, neg)\n",
    "\n",
    "\t\tin_channels : Number of input channels. Here it is 1 as the input data has dimension = (batch_size, num_seq, embedding_length)\n",
    "\n",
    "\t\tout_channels : Number of output channels after convolution operation performed on the input matrix\n",
    "\n",
    "\t\tkernel_heights : A list consisting of 3 different kernel_heights. Convolution will be performed 3 times and finally results from each kernel_height will be concatenated.\n",
    "\n",
    "\t\tkeep_probab : Probability of retaining an activation node during dropout operation\n",
    "\n",
    "\t\tvocab_size : Size of the vocabulary containing unique words\n",
    "\n",
    "\t\tembedding_length : Embedding dimension of GloVe word embeddings\n",
    "\n",
    "\t\tweights : Pre-trained GloVe word_embeddings which we will use to create our word_embedding look-up table\n",
    "\n",
    "\t\t--------\n",
    "\n",
    "\t\t\n",
    "\n",
    "\t\t\"\"\"\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.output_size = output_size\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_heights = kernel_heights\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_length = embedding_length\n",
    "\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_length)\n",
    "        self.word_embeddings.weight = nn.Parameter(weights, requires_grad=False)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, (kernel_heights[0], embedding_length), stride, padding)\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, (kernel_heights[1], embedding_length), stride, padding)\n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels, (kernel_heights[2], embedding_length), stride, padding)\n",
    "        self.dropout = nn.Dropout(keep_probab)\n",
    "        self.label = nn.Linear(len(kernel_heights)*out_channels, output_size)\n",
    "\n",
    "    def conv_block(self, input, conv_layer):\n",
    "\n",
    "        conv_out = conv_layer(input)# conv_out.size() = (batch_size, out_channels, dim, 1)\n",
    "        activation = F.relu(conv_out.squeeze(3))# activation.size() = (batch_size, out_channels, dim1)\n",
    "        max_out = F.max_pool1d(activation, activation.size()[2]).squeeze(2)# maxpool_out.size() = (batch_size, out_channels)\n",
    "\n",
    "        return max_out\n",
    "\n",
    "\n",
    "    def forward(self, input_sentences, batch_size=None):\n",
    "\n",
    "\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tThe idea of the Convolutional Neural Netwok for Text Classification is very simple. We perform convolution operation on the embedding matrix \n",
    "\n",
    "\t\twhose shape for each batch is (num_seq, embedding_length) with kernel of varying height but constant width which is same as the embedding_length.\n",
    "\n",
    "\t\tWe will be using ReLU activation after the convolution operation and then for each kernel height, we will use max_pool operation on each tensor \n",
    "\n",
    "\t\tand will filter all the maximum activation for every channel and then we will concatenate the resulting tensors. This output is then fully connected\n",
    "\n",
    "\t\tto the output layers consisting two units which basically gives us the logits for both positive and negative classes.\n",
    "\n",
    "\t\t\n",
    "\n",
    "\t\tParameters\n",
    "\n",
    "\t\t----------\n",
    "\n",
    "\t\tinput_sentences: input_sentences of shape = (batch_size, num_sequences)\n",
    "\n",
    "\t\tbatch_size : default = None. Used only for prediction on a single sentence after training (batch_size = 1)\n",
    "\n",
    "\t\t\n",
    "\n",
    "\t\tReturns\n",
    "\n",
    "\t\t-------\n",
    "\n",
    "\t\tOutput of the linear layer containing logits for pos & neg class.\n",
    "\n",
    "\t\tlogits.size() = (batch_size, output_size)\n",
    "\n",
    "\t\t\n",
    "\n",
    "\t\t\"\"\"\n",
    "\n",
    "\n",
    "        input = self.word_embeddings(input_sentences)\n",
    "        # input.size() = (batch_size, num_seq, embedding_length)\n",
    "        input = input.unsqueeze(1)\n",
    "        # input.size() = (batch_size, 1, num_seq, embedding_length)\n",
    "        max_out1 = self.conv_block(input, self.conv1)\n",
    "        max_out2 = self.conv_block(input, self.conv2)\n",
    "        max_out3 = self.conv_block(input, self.conv3)\n",
    "\n",
    "\n",
    "        all_out = torch.cat((max_out1, max_out2, max_out3), 1)\n",
    "        # all_out.size() = (batch_size, num_kernels*out_channels)\n",
    "\n",
    "        fc_in = self.dropout(all_out)\n",
    "\n",
    "        # fc_in.size()) = (batch_size, num_kernels*out_channels)\n",
    "\n",
    "        logits = self.label(fc_in)\n",
    "\n",
    "\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on new data (115th Congress)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
